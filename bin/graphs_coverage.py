#!/usr/bin/env python

'''
=============================================================
HEADER
=============================================================
INSTITUTION: BU-ISCIII

AUTHOR: Guillermo J. Gorines Cordero

MAIL: guillermo.gorines@urjc.es

VERSION: 1.0

CREATED: Exact date unknown (late 2020)

REVISED: 26-5-2021

DESCRIPTION: 
    Calculates coverage statistics (mean, median) for the coverage files provided, 
    and generates HTML plots of the coverage vs the % of reads that present such 
    coverage (for each alignment in the given coverage files).

INPUT (by order):
    1. Sample name (will be used to name the outdir)
    2. Organism type (virus, bacteria, fungi initially)
    3. Assemblies data (as generated by Download_assemblies.py)
        Please check format requirements in pikavirus wiki
    4 and on. Coverage files 

OUTPUT:
    1. TXT containing statistics for each coverage file including taxid, organism name
    2. HTML plots (one for each alignment on the coverage file)

USAGE:
    graphs_coverage.py samplename coveragefiles

REQUIREMENTS:
    -Python >= 3.6
    -Pandas
    -Numpy
    -Plotly

DISCLAIMER: this script has exclusively been developed for nf-core pikavirus, andtherefore 
is not guaranteed to function properly in other settings. Despite this, feel free to use it
at will.


TO DO: 

================================================================
END_OF_HEADER
================================================================
'''

# Imports
import sys
import os
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import plotly.offline

# Needed functions
def weighted_avg_and_std(df,values, weights):
    average = np.average(df[values], weights=df[weights])
    variance = np.average((df[values]-average)**2, weights=df[weights])
    
    return (average, variance**0.5)

def calculate_weighted_median(df, values, weights):
    cumsum = df[weights].cumsum()
    cutoff = df[weights].sum() * 0.5
    
    return df[cumsum >= cutoff][values].iloc[0]

def calculate_weighted_quartiles(df, values, weights):
    cumsum = df[weights].cumsum()
    cutoff_25 = df[weights].sum() * 0.25
    cutoff_75 = df[weights].sum() * 0.75

    quartile_25 = df[cumsum >= cutoff_25][values].iloc[0]
    quartile_75 = df[cumsum >= cutoff_75][values].iloc[0]

    return quartile_25, quartile_75


# args managent
sample_name=sys.argv[1]
organism_type=sys.argv[2]
species_data=sys.argv[3]
coverage_files=sys.argv[4:]

with open(species_data) as species_data:
    species_data = species_data.readlines()

# Get headers and data
headers = [line.strip("\n").split("\t") for line in species_data if line.startswith("#")]
species_data = [line.strip("\n").split("\t") for line in species_data if not line.startswith("#")]

# Identify required columns through headers
file_headers = ["filename","file_name","file-name","file"]
species_name_headers = ["scientific_name","organism_name","organism","species_name","species"]
subspecies_name_headers = ["intraespecific_name","subspecies_name","strain","subspecies"]

for single_header in headers:
    for item in single_header:
        if item.lower() in file_headers:
            file_column_index = single_header.index(item)

        elif item.lower() in species_name_headers:  
            species_column_index = single_header.index(item)

        elif item.lower() in subspecies_name_headers:
            subspecies_column_index = single_header.index(item)

# Exit with error status if one of the required groups is not identified
if not file_column_index or not species_column_index or not subspecies_column_index:
    if not file_column_index:
        print(f"No headers indicating \"File name\" were found in the reference file.")
    if not species_column_index:
        print(f"No headers indicating \"Species name\" were found in the reference file.")
    if not subspecies_column_index:
        print(f"No headers indicating \"Subspecies name\" were found in the reference file.")

    print(f"Please consult the reference sheet format, sorry for the inconvenience!")
    sys.exit(1)

species_data = [[line[species_column_index], line[subspecies_column_index], line[file_column_index]] for line in species_data]

# Remove the extension of the file (so it matches the filename)
extensions = [".gz",".fna"]

species_data_noext = []

for item in species_data:
    filename_noext = item[2]
    for extension in extensions:
        filename_noext=filename_noext.replace(extension,"")

    species_data_noext.append([item[0],item[1],filename_noext])

coverage_files_w_species = []

# Parse coverage files

for item in coverage_files:

    match_name_coverage = item.replace(".sam","").split("_vs_")[0]
    for extension in extensions:
        match_name_coverage = match_name_coverage.replace(extension,"")

    for name in species_data_noext:

        if name[2] == match_name_coverage:
            species = name[0]
            subspecies = name[1]

            with open(item,"r") as infile:
                infiledata = [line.strip("\n") for line in infile.readlines()]
                infiledata = [line.split("\t") for line in infiledata]

            if subspecies:
                spp_filename = f"{species}_{subspecies}"
            else:
                subspecies = "--"
                spp_filename = f"{species}"
            
            newitem = f"covfile_{name[2]}_{spp_filename}.tsv".replace(" ","_").replace("=",":").replace("/","_")
            coverage_files_w_species.append(newitem)

            # generate boxplot
            # fill dict to create dict 

            dict_for_boxplot = {}

            for line in infiledata:   

                if line[0] not in dict_for_boxplot.keys():
                    dict_for_boxplot[line[0]] = []
                
                dict_for_boxplot[line[0]].extend([int(line[1])] * int(line[2]))

            # remove if coverage is 0
            for key, values in dict_for_boxplot.items():
                if max(values) = 0:
                    del dict_for_boxplot[key]

            boxplot_full = go.Figure()

            for key, values in dict_for_boxplot.items():

                if key == "genome":
                    boxname == "whole genome"
                    file_key = f"{spp_filename}_genome"
                else:
                    file_key = key
                    boxname = key

                single_boxplot = go.Figure()
                
                boxplot = go.Box(y=values, name = boxname, boxmean = "sd")
                
                single_boxplot.add_trace(boxplot)
                boxplot_full.add_trace(boxplot)

                single_boxplot.update_layout(title_text = f"{sample_name}, {spp_filename}",
                                             yaxis_title = "Coverage Depth")

                plotly.offline.plot({"data": single_boxplot},
                            auto_open = False,
                            filename = f"{file_key}_{sample_name}_single_boxplot.html")

            boxplot_full.update_layout(title_text = f"{sample_name}, {spp_filename} boxplot",
                                       yaxis_title = "Coverage Depth")

            plotly.offline.plot({"data": boxplot_full},
                        auto_open = False,
                        filename = f"{spp_filename}_{sample_name}_full_boxplot.html")

            with open(newitem,"w") as outfile:
                for line in infiledata:
                    if line[0] == "genome":
                        line[0] = f"{species}_{subspecies}_genome"

                        if len(infiledata) == 2:
                            filedata ="\t".join(line)
                            outfile.write(f"{filedata}\t{species}\t{subspecies}\n") 
                            pass

                    filedata ="\t".join(line)
                    outfile.write(f"{filedata}\t{species}\t{subspecies}\n")
               


dataframe_list = []

for filename in coverage_files_w_species:
    tmp_dataframe = pd.read_csv(filename,sep="\t",header=None)
    dataframe_list.append(tmp_dataframe)

if len(dataframe_list) > 1:
    df = pd.concat(dataframe_list)
else:
    df = dataframe_list[0]

df.columns=["gnm","covDepth","BasesAtThisCoverage","genomeLength","FracOnThisDepth","Species","Subspecies"]

df["FracOnThisDepth_cumsum"] = df.groupby('gnm')['FracOnThisDepth'].transform(pd.Series.cumsum)
df["FracWithMoreDepth"] = 1 - df["FracOnThisDepth_cumsum"]
df["FracWithMoreDepth_percentage"] = df["FracWithMoreDepth"]*100

data = {"gnm":[],"species":[],"subspecies":[],"covMean":[],"covMin":[],"covMax":[],"covSD":[],"covMedian":[],
        ">x1":[],">x50":[],">x100":[]}

for name, df_grouped in df.groupby("gnm"):

    mean, covsd = weighted_avg_and_std(df_grouped,"covDepth","FracOnThisDepth")
    
    if mean == 0:
        continue
    
    minimum = min(df_grouped["covDepth"])
    maximum = max(df_grouped["covDepth"])
    median = calculate_weighted_median(df_grouped,"covDepth","FracOnThisDepth")

    species = df_grouped.iloc[0]["Species"]
    subspecies = df_grouped.iloc[0]["Subspecies"]


    data["gnm"].append(name)
    data["species"].append(species)
    data["subspecies"].append(subspecies)
    data["covMean"].append(mean)
    data["covMin"].append(minimum)
    data["covMax"].append(maximum)
    data["covSD"].append(covsd)
    data["covMedian"].append(median)
    
    y0=df_grouped.FracOnThisDepth[(df_grouped["covDepth"] > 1)].sum()
    y1=df_grouped.FracOnThisDepth[(df_grouped["covDepth"] > 50)].sum()
    y2=df_grouped.FracOnThisDepth[(df_grouped["covDepth"] > 100)].sum()

    
    data[">x1"].append(y0)
    data[">x50"].append(y1)
    data[">x100"].append(y2)

    

    fig = px.line(df_grouped,
                  x="covDepth",
                  y="FracWithMoreDepth_percentage",
                  labels={"covDepth":"Coverage Depth",
                  "FracWithMoreDepth_percentage":"Proportion of bases above depth (%)"})
    fig.update_yaxes(range=[0,100], dtick=5)

    if "genome" in name:
        name = "genome"


    if subspecies == "--":
        filename = f"{sample_name}_{organism_type}_{species}_{name}"
    else:
        filename = f"{sample_name}_{organism_type}_{species}_{subspecies}_{name}"


    plotly.offline.plot({"data": fig},
                        auto_open = False,
                        filename = f"{filename}.html" )

newcov = pd.DataFrame.from_dict(data)
newcov.to_csv(f"{sample_name}_{organism_type}_table.csv")
